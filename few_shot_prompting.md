# Few-Shot Prompting

大規模言語モデルは優れたゼロショット能力を発揮しますが、ゼロショット設定を用いた場合、より複雑なタスクでは依然として不十分です。少数ショットプロンプトは、コンテキスト内学習を可能にする手法として使用できます。プロンプト内でデモンストレーションを提供することで、モデルのパフォーマンス向上を促します。デモンストレーションは、モデルに応答を生成させたい後続の例題に対する条件付けとして機能します。

Touvron et al. 2023 によると、少数ショットの特性は、モデルが十分な規模にスケールされたときに初めて現れました (Kaplan et al., 2020)。

Brown et al. 2020 で示された例を用いて、少数ショットのプロンプティングを説明しましょう。この例では、新しい単語を文中で正しく使用するという課題が与えられます。

Prompt:
```
「Whatpu」はタンザニア原産の小さくて毛むくじゃらの動物です。「Whatpu」を使った例文は以下の通りです。
私たちはアフリカを旅行していて、とてもかわいい「Whatpu」を見ました。

「farduddle」とは、とても速く飛び跳ねることを意味します。「farduddle」を使った例文は以下の通りです。
```
```
A "whatpu" is a small, furry animal native to Tanzania. An example of a sentence that uses the word whatpu is:
We were traveling in Africa and we saw these very cute whatpus.
 
To do a "farduddle" means to jump up and down really fast. An example of a sentence that uses the word farduddle is:
```

Output:
```
試合に勝ったとき、私たちは全員で祝杯をあげ始めました。
```
```
When we won the game, we all started to farduddle in celebration.
```


モデルにたった1つの例（1ショット）を与えるだけで、タスクの実行方法を学習したことがわかります。より難しいタスクの場合は、デモンストレーションの数を増やして実験することができます（例：3ショット、5ショット、10ショットなど）。

Min et al. (2022) の調査結果を受けて、few-shot を行う際のデモンストレーション/例に関するヒントをいくつか紹介します。

- 「ラベル空間と、デモンストレーションで指定された入力テキストの分布はどちらも重要です（個々の入力に対してラベルが正しいかどうかに関係なく）」
- 使用する形式もパフォーマンスに重要な役割を果たします。ランダムなラベルを使用するだけでも、ラベルを全く使用しないよりははるかに優れています。
- 追加の結果によると、ラベルの真の分布（一様分布ではなく）からランダムなラベルを選択することも効果的です。

いくつか例を試してみましょう。まずはランダムラベル（つまり、NegativeとPositiveというラベルが入力にランダムに割り当てられる）を使った例を試してみましょう。


Prompt:
```
これは最高！ // Negative
これは最悪！ // Positive
わあ、あの映画は最高だった！ // Positive
なんてひどい番組なんだ！ //
```
```
This is awesome! // Negative
This is bad! // Positive
Wow that movie was rad! // Positive
What a horrible show! //
```

Output
```
Negative
```

ラベルがランダム化されているにもかかわらず、正しい答えが得られています。フォーマットも維持されている点に注目してください。これも役立っています。実際、さらなる実験を重ねるうちに、私たちが実験している新しいGPTモデルは、ランダムなフォーマットに対してもより堅牢になっているようです。例：

Prompt:
```
ポジティブ：最高！
これは最悪！ ネガティブ：わあ、あの映画は最高だった！
ポジティブ：なんてひどい番組なんだ！ --
```
```
Positive This is awesome! 
This is bad! Negative
Wow that movie was rad!
Positive
What a horrible show! --
```

Output:
```
Negative
```

上記の形式には一貫性がありませんが、モデルは正しいラベルを予測しました。プロンプトのバリエーションを含む、より複雑な異なるタスクにもこれが当てはまるかどうかを確認するには、より徹底的な分析を行う必要があります。

## Limitations of Few-shot Prompting
標準的な数ショットプロンプトは多くの課題で有効ですが、特に複雑な推論課題を扱う場合には、依然として完璧な手法とは言えません。なぜそうなのかを説明しましょう。前回の例では、次のような課題を与えました。

```
このグループの奇数を足すと偶数になります: 15、32、5、13、82、7、1。
A:
```
```
The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. 
A: 
```

これをもう一度試すと、モデルは次のように出力します。
```
はい、このグループの奇数を合計すると 107 となり、偶数になります。
```
```
Yes, the odd numbers in this group add up to 107, which is an even number.
```

これは正しい回答ではありません。これは、これらのシステムの限界を浮き彫りにするだけでなく、より高度なプロンプトエンジニアリングの必要性を示唆しています。

少数発話のプロンプトによって結果が改善されるかどうかを確認するために、いくつか例を追加してみましょう。

Prompt
```
このグループの奇数を足すと偶数になります。4、8、9、15、12、2、1。
A: 答えは偽です。
このグループの奇数を足すと偶数になります。17、10、19、4、8、12、24。
A: 答えは真です。
このグループの奇数を足すと偶数になります。16、11、14、4、8、13、24。
A: 答えは真です。
このグループの奇数を足すと偶数になります。17、9、10、12、13、4、2。
A: 答えは偽です。
このグループの奇数を足すと偶数になります。15、32、5、13、82、7、1。
A:
```
```
The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.
A: The answer is False.
The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.
A: The answer is True.
The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.
A: The answer is True.
The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.
A: The answer is False.
The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. 
A: 
```

Output
```
The answer is True.
```


それはうまくいきませんでした。この種の推論問題では、少量のプロンプトだけでは信頼できる回答を得るのに不十分なようです。上記の例は、課題に関する基本的な情報を示しています。詳しく見てみると、私たちが導入したタイプの課題には、さらにいくつかの推論ステップが含まれていることがわかります。つまり、問題をステップに分解し、それをモデルに示すことが役立つかもしれません。最近では、思考連鎖（CoT）プロンプトが、より複雑な算術、常識、記号推論の課題に対処するために普及しています。

全体的に見て、例を提供することは、いくつかのタスクを解決するのに役立つようです。ゼロショットプロンプティングや数ショットプロンプティングが不十分な場合、モデルが学習した内容だけではタスクをうまく実行できない可能性があります。ここからは、モデルの微調整や、より高度なプロンプティング手法の実験を検討することをお勧めします。次に、人気の高いプロンプティング手法の一つである「思考連鎖プロンプティング」について説明します。これは非常に人気が高まっています。